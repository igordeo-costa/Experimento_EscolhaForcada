theme_classic() + ylim(0,1)+
ylab("Frequência de produção (%)") + xlab("") +
ggtitle("") +
facet_wrap(~FAIXA.ETARIA) +
theme(legend.position = "none")
intervalos <- perc %>%
mutate(ci_inf=porc-1.96*SE) %>% # Calcula o limite mínimo do IC
mutate(ci_inf=if_else(ci_inf<0, 0, ci_inf)) %>% # Evita intervalos menores do que zero
mutate(ci_sup=porc+1.96*SE) # Calcula o limite máximo do intervalo de confiança
intervalos
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 4, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
ggtitle("Intervalo de confiança (95%) da proporção")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 4, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
ggtitle()
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 4, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
theme(text = element_text(size=20))
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
theme(text = element_text(size=14))
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
theme(text = element_text(size=14),
legend.title = element_blank())
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
require(scales)
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent_format(scale = 1)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent_format(scale = 5)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent_format(scale = 1)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent_format(scale = 0)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent_format(scale = 1)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
#  scale_y_continuous(labels = scales::percent_format(scale = 1)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
# E fazer o gráfico:
ggplot(intervalos, aes(x=PAD.INT, y=porc, colour=FAIXA.ETARIA)) +
geom_errorbar(aes(ymin=ci_inf, ymax=ci_sup),
width=.2, size=0.9, position=position_dodge(.3)) +
geom_point(position = position_dodge(width = 0.3),
fill="white", size = 2, shape=21, stroke = 1)+
coord_flip()+ theme_classic() + ylim(0,1) +
ylab("Frequência de erros (%)") + xlab("") +
scale_y_continuous(labels = scales::percent) +
theme(text = element_text(size=14),
legend.title = element_blank(),
legend.position = "top")
ggsave("Cristina.png", dpi = 300, width = 1750, height = 1550, units = "px")
# Cristina, nesse gráfico aí, a gente filtrou os padrões que interessavam, não é?
pad.interesse <- newdata %>%
filter(TIPO.EST1=="Num+N+Adj") %>%
filter(PAD.INT %in% c("SSS", "SSO", "SOO", "SOS"))
perc <- pad.interesse %>%
group_by(FAIXA.ETARIA, PAD.INT) %>%
tally() %>% # Faz a contagem
mutate(porc=n/sum(n)) %>% # Calcula a porcentagem
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) # Limita os valores inferiores a zero
# Plotar um gráfico com as porcentagens e erro padrão:
ggplot(perc, aes(x = PAD.INT, y = porc, fill = PAD.INT))+
geom_bar(stat = "identity", position = position_dodge(), color="black") +
geom_errorbar(aes(ymin=SE_inf, ymax=SE_sup), width=.1, size=1,
position=position_dodge()) +
theme_classic() + ylim(0,1)+
ylab("Frequência de produção (%)") + xlab("") +
ggtitle("") +
facet_wrap(~FAIXA.ETARIA) +
theme(legend.position = "none")
# Plotar um gráfico com as porcentagens e erro padrão:
ggplot(perc, aes(x = PAD.INT, y = porc, fill = PAD.INT))+
geom_bar(stat = "identity", position = position_dodge(), color="black") +
geom_errorbar(aes(ymin=SE_inf, ymax=SE_sup), width=.1, size=1,
position=position_dodge()) +
theme_classic() + ylim(0,1)+
ylab("Frequência de produção (%)") + xlab("") +
ggtitle("") +
facet_wrap(~FAIXA.ETARIA) +
theme(legend.position = "none") +
theme(text = element_text(size=14))
# Plotar um gráfico com as porcentagens e erro padrão:
ggplot(perc, aes(x = PAD.INT, y = porc, fill = PAD.INT))+
geom_bar(stat = "identity", position = position_dodge(), color="black") +
geom_errorbar(aes(ymin=SE_inf, ymax=SE_sup), width=.1, size=1,
position=position_dodge()) +
theme_classic() + ylim(0,1)+
ylab("Frequência de produção (%)") + xlab("") +
ggtitle("") +
facet_wrap(~FAIXA.ETARIA) +
scale_y_continuous(labels = scales::percent) +
theme(legend.position = "none") +
theme(text = element_text(size=14))
# Função para limpeza dos dados
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
if (auto.colnames){
cols <- c()
con <- file(filepath, "r")
while ( TRUE ) {
line <- readLines(con, n = 1, warn=FALSE)
if ( length(line) == 0) {
break
}
m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
if (length(m) == 3) {
index <- as.numeric(m[2])
value <- m[3]
if (is.function(fun.col)){
cols <- fun.col(value,cols)
}
cols[index] <- value
if (index == n.cols){
break
}
}
}
close(con)
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
}
else{
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
}
}
# Pacotes necessários
require(dplyr)
require(tidyr)
require(stringr)
require(ggplot2)
require(scales)
require(forcats)
require(RColorBrewer)
require(gridExtra)
# Diretório de trabalho
setwd("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/EscolhaForcada/Resultados")
# Carregamento dos dados
dados <- read.pcibex("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/EscolhaForcada/Resultados/Backup_ResultadosFinal_122Part.csv")
#-------------------------------------------------------------------------------
# Filtrando apenas os dados das sentenças 'teste'
#-------------------------------------------------------------------------------
clean_data <- dados %>%
filter(Inner.element.number %in% c("trein", "distrat", "experiment")) %>%
select(-c("Controller.name", "Order.number.of.item", "Label", "nativo"))
colnames(clean_data) <- c("UniqueReceptionTime", "MD5_Hash", "Label", "PennType", "PennName",
"Parameter", "Escolha", "EventTime", "vies", "item", "frase", "lista",
"genero", "escolaridade", "nativo")
clean_data <- clean_data %>%
filter(vies %in% c("coletivo", "distributivo", "teste"))
#-------------------------------------------------------------------------------
# Analisando os critérios de exclusão
#-------------------------------------------------------------------------------
# Falante nativo & taxa mínima de respostas às distratoras imcompatível com o mínimo
# Ver abaixo, na análise das distratoras, por que tiramos esses dois participantes
clean_data <- clean_data %>%
filter(nativo == "Sim") %>%
filter(!UniqueReceptionTime %in% c("1632311528", "1631919148"))
# Dados de escolaridade (exclusão)
clean_data %>%
group_by(UniqueReceptionTime, escolaridade) %>%
tally() %>%
group_by(UniqueReceptionTime, escolaridade) %>%
summarise(n = n/n) %>%
group_by(escolaridade) %>%
tally()
# Exclusão dos participantes que não atenderam ao critério de escolaridade
clean_data <- clean_data %>%
filter(!escolaridade %in% c("Ensino Fundamental incompleto", "Ensino Médio incompleto"))
# Análise das declarações de gênero
clean_data %>%
group_by(UniqueReceptionTime, genero) %>%
tally() %>%
group_by(UniqueReceptionTime, genero) %>%
summarise(n = n/n) %>%
group_by(genero) %>%
tally()
# Essa a lista final de participantes por lista
listas <- as.data.frame(table(clean_data$UniqueReceptionTime, clean_data$lista))
colnames(listas) <- c("IDPart", "Lista", "Quantidade")
listas <- listas %>%
group_by(Lista) %>%
mutate(Quantidade = Quantidade/Quantidade) %>%
summarise(Quantidade = sum(Quantidade, na.rm = T))
# Exportando essa tabela para o material escrito
# write.csv(listas, "ParticipantesPorLista.csv")
#-------------------------------------------------------------------------------
# Análise das sentenças distratoras
#-------------------------------------------------------------------------------
dist <- dados %>%
filter(Inner.element.number %in% c("distrat")) %>%
select(-c("Controller.name", "Order.number.of.item", "Label", "nativo"))
colnames(dist) <- c("UniqueReceptionTime", "MD5_Hash", "Label", "PennType", "PennName",
"Parameter", "Escolha", "EventTime", "vies", "item", "frase", "posicao",
"genero", "escolaridade", "nativo")
# Carregando a tabela com a resposta esperada por cada frase direto do GitHub
expected_answers <- read.csv("https://raw.githubusercontent.com/igordeo-costa/Experimento_EscolhaForcada/main/Estudo%20normativo/chunk_includes/Distratores.csv")
# Uma frase distratora foi catalogada erroneamente, de modo que havia 17 (e não 16) com resposta esperada + de um
# O código abaixo conserta isso
expected_answers <- expected_answers %>%
mutate(resposta = ifelse(frase == "Os pedreiros moveram alguns tijolos.", "+um", resposta))
# Mesclando as duas tabelas e filtrando apenas respostas à escolha forçada
dist <- expected_answers %>%
select(c(posicao, resposta, frase)) %>%
inner_join(dist, by = c("frase", "posicao")) %>%
filter(Parameter == "Choice") %>%
mutate(Escolha = str_replace_all(Escolha, c("uma" = "um"))) %>%
filter(Escolha %in% c("Apenas um", "Mais de um"))
# Análise por sujeitos
dist$UniqueReceptionTime <- as.factor(dist$UniqueReceptionTime)
# Análise das distratoras por frase
cores <- brewer.pal(name = "Set1", n = 2)
dist %>%
group_by(resposta, UniqueReceptionTime, Escolha) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Escolha == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
ggplot(aes(x = UniqueReceptionTime, y = porc, color = resposta)) +
geom_hline(aes(yintercept = 0.5), linetype = "dashed", color = "grey60") +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14),
axis.text.y = element_blank(),
axis.ticks.y = element_blank())
# Participantes que tiveram respostas no nível da chance:
# 1632311528
# 1631919148
# Análise global das distratoras
dist %>%
filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
group_by(resposta, Escolha) %>%
tally() %>%
mutate(porc = n/sum(n))
dist %>%
filter(!UniqueReceptionTime %in% c("1632311528", "1631919148")) %>%
group_by(resposta, frase, Escolha) %>%
tally() %>%
mutate(porc = n/sum(n, na.rm = T)) %>%
mutate(SE=sqrt((porc*(1-porc))/n)) %>% # Calcula o erro padrão (Standad Error ou SE) da proporção
mutate(SE_inf=porc-SE) %>%
mutate(SE_sup=porc+SE) %>%
mutate(SE_inf=if_else(SE_inf<0, 0, SE_inf)) %>%
filter(Escolha == "Apenas um") %>% # Ou "Mais de um" aqui... Tanto faz...
ggplot(aes(x = frase, y = porc, color = resposta)) +
geom_errorbar(aes(ymin = SE_inf, ymax = SE_sup), width = 0.3, size = 0.7, color = "grey") +
geom_point(size = 2, stroke = 1, fill = "white", shape = 21) +
coord_flip() +
theme_classic() +
scale_y_continuous(labels = scales::label_percent(accuracy = 1L)) +
scale_color_manual(values = cores, name = "Resposta Esperada:",
labels = c("Mais de um", "Apenas um")) +
labs(x = "", y = "") +
theme(text = element_text(size=14),
legend.position = "top",
legend.text = element_text(size=14))
#-------------------------------------------------------------------------------
# Análise dos dados das sentenças-teste
#-------------------------------------------------------------------------------
# Modificando as expressões 'uma' em 'um' para facilitar a análise
choice_data <- clean_data %>%
filter(Parameter == "Choice") %>%
mutate(Escolha = str_replace_all(Escolha, c("uma" = "um")))
# Agora temos uma coluna apenas com as respostas ("Escolha")
# Vamos separar em dois grupos a escolha forçada ("resposta" em "PennName")
# e o julgamento ("minhaescala" em PennName)
missing_data <- choice_data %>%
filter(PennName == "resposta") %>%
mutate_if(is.character, as.factor) %>%
mutate_if(is.integer, as.factor) %>%
group_by(vies, lista) %>%
tally(is.na(Escolha))
# Total de respostas à pergunta é à escala
choice_data %>%
group_by(PennName) %>%
tally()
# Diferença entre respostas perdidas e total de respostas
1856-1751
# Apenas conferindo
missing_data %>%
summarise(total = sum(n)) %>%
summarise(total = sum(total))
# Calculando a porcentagem
round(105/1751*100, 2)
# Exportar a tabela missing_data
#-------------------------------------------------------------------------------
# Preparando a tabela final de dados a ser usada nas análises
#-------------------------------------------------------------------------------
# Pareando escolha forçada com julgamentos correspondentes
escala <- choice_data %>%
pivot_wider(values_from = Escolha, names_from = PennName) %>%
filter(!is.na(minhaescala)) %>%
select(-c("resposta"))
forced_choice <- choice_data %>%
pivot_wider(values_from = Escolha, names_from = PennName) %>%
filter(!is.na(resposta)) %>%
select(-c("minhaescala"))
head(forced_choice)
forced_choice$minhaescala <- escala$minhaescala
choice_data <- forced_choice
setwd("/home/dados/Acadêmicos/Doutorado/EXPERIMENTOS_2021/EscolhaForcada/Experimento_EscolhaForcada/Resultados/")
write.csv(choice_data, "dadoslimpos.csv")
# Carregamento dos dados
dados <- read.pcibex("https://raw.githubusercontent.com/igordeo-costa/Experimento_EscolhaForcada/main/Resultados/ResultadosPCIbex.csv")
# Função para limpeza dos dados
read.pcibex <- function(filepath, auto.colnames=TRUE, fun.col=function(col,cols){cols[cols==col]<-paste(col,"Ibex",sep=".");return(cols)}) {
n.cols <- max(count.fields(filepath,sep=",",quote=NULL),na.rm=TRUE)
if (auto.colnames){
cols <- c()
con <- file(filepath, "r")
while ( TRUE ) {
line <- readLines(con, n = 1, warn=FALSE)
if ( length(line) == 0) {
break
}
m <- regmatches(line,regexec("^# (\\d+)\\. (.+)\\.$",line))[[1]]
if (length(m) == 3) {
index <- as.numeric(m[2])
value <- m[3]
if (is.function(fun.col)){
cols <- fun.col(value,cols)
}
cols[index] <- value
if (index == n.cols){
break
}
}
}
close(con)
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=cols))
}
else{
return(read.csv(filepath, comment.char="#", header=FALSE, col.names=seq(1:n.cols)))
}
}
# Carregamento dos dados
dados <- read.pcibex("https://raw.githubusercontent.com/igordeo-costa/Experimento_EscolhaForcada/main/Resultados/ResultadosPCIbex.csv")
# Pacotes necessários
require(dplyr)
require(tidyr)
require(stringr)
require(ggplot2)
require(scales)
require(forcats)
require(RColorBrewer)
require(gridExtra)
#-------------------------------------------------------------------------------
# Filtrando apenas os dados das sentenças 'teste'
#-------------------------------------------------------------------------------
clean_data <- dados %>%
filter(Inner.element.number %in% c("trein", "distrat", "experiment")) %>%
select(-c("Controller.name", "Order.number.of.item", "Label", "nativo"))
colnames(clean_data) <- c("UniqueReceptionTime", "MD5_Hash", "Label", "PennType", "PennName",
"Parameter", "Escolha", "EventTime", "vies", "item", "frase", "lista",
"genero", "escolaridade", "nativo")
clean_data <- clean_data %>%
filter(vies %in% c("coletivo", "distributivo", "teste"))
